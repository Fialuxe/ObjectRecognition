以下はアップロードされたHTMLファイルの内容をMarkdown形式に変換したものです。

---

# 物体認識論 演習 レポート課題

## Web画像を用いた物体認識実験 (本講義のまとめの実験課題)

最後にまとめとして，演習の第6回までに作成した画像認識システムをWeb画像検索の出力に適用して，Web画像検索の精度を高める実験を行います．この実験は最終レポート課題となりますので，最後まで頑張ってシステムを完成させて下さい．

### Webからの画像収集

プログラムによるWebからの画像収集は，画像共有サイトのFlickrや，画像検索エンジンのBing画像検索などを提供するWebAPIを用いることで簡単に実現できます．

~~Bing API~~, Flickr Web API, ~~Instagram API~~ (Bing APIは有料化のため，Instagram APIはポリシー変更で利用にアプリ審査が必要になったので利用を断念しました)を利用して，キーワードを入力すると指定枚数の画像のURLリストを表示するCGIを用意しましたので，それを利用してWebから画像を集めましょう．

[Flickr (sushi) (ORDER: relevance)](https://www.google.com/search?q=http://mm.cs.uec.ac.jp/tutorial/flickr.cgi%3FWORD%3Dsushi%26ORDER%3D4)

(Instagramが利用できなくなったので，代わりにFlickrAPIサイトの表示順のデフォルトを投稿時間順として，ノイズが多くなるようにしました．ですので，学習データをFlickrから探す場合は，ORDERを relevance か interesting にしてください．そうすると，ノイズの少ない画像になるでしょう．(【参考】[Flickr (sushi) (ORDER:latest)](https://www.google.com/search?q=http://mm.cs.uec.ac.jp/tutorial/flickr.cgi%3FWORD%3Dsushi%26ORDER%3D0) latestはノイズが多い傾向があります) を利用してください.

Flickrは画像共有Flickrサイトのキーワード検索で，写真をアップしたユーザが付与したキーワードに基づく検索なので，Web検索エンジンと違って，精度はあまりよくありません．なお，同じ単語でも，検索語が日本語と英語だと結果は異なります．

Flickrの場合は，様々な大きさの画像が用意されています．画像の末尾が `.jpg` の場合は長辺が500ピクセル, `_n.jpg` は320, `_m` は240, `_q.jpg` は150x150の正方画像などです．

画像認識実験では長辺320ピクセルの画像で十分ですので，Flickrを使う場合は `_n.jpg` の画像を使うようにしましょう．(もちろん，`.jpg`でも構いません．)

まず，上記のどれかの画像URL表示ページを使って，以下のような画像URLリストをテキストファイルにセーブしてください．

```text
http://farm4.static.flickr.com/3906/14875575965_2748fb8fae_n.jpg
http://farm5.static.flickr.com/4709/38918253275_94ccafea0d_n.jpg
http://farm4.static.flickr.com/3649/3345340423_332a48b475_n.jpg
http://farm4.static.flickr.com/3844/15116521856_dfef928f7b_n.jpg
http://farm8.static.flickr.com/7406/12576230525_c786df3303_n.jpg
http://farm9.static.flickr.com/8097/8490311843_06520c35ea_n.jpg

```

上記の内容が，`urllist.txt` に入っているとします．あとは，[textread](http://jp.mathworks.com/help/matlab/ref/textread.html) でファイルを読み込んで，[websave](http://jp.mathworks.com/help/matlab/ref/websave.html) でファイルにダウンロードするか，[webread](http://jp.mathworks.com/help/matlab/ref/webread.html) でWeb上の画像ファイルを直接読み込みましょう．

```matlab
list=textread('urllist.txt','%s');

% 読んだテキストはセル配列に読み込まれます．

>> list
list =
    'http://farm4.static.flickr.com/3906/14875575965_2748fb8fae_n.jpg'
    'http://farm5.static.flickr.com/4709/38918253275_94ccafea0d_n.jpg'
    'http://farm4.static.flickr.com/3649/3345340423_332a48b475_n.jpg'
    'http://farm4.static.flickr.com/3844/15116521856_dfef928f7b_n.jpg'
    'http://farm8.static.flickr.com/7406/12576230525_c786df3303_n.jpg'

>> size(list)
ans =
    5     1

>> list{1}
ans =
http://farm4.static.flickr.com/3906/14875575965_2748fb8fae_n.jpg

% websave でMATLABで画像ファイルをダウンロードしてみましょう．
% 以下を実行すると，imgdir に画像が 0001.jpg, ... としてsaveされます．

OUTDIR='imgdir';
mkdir(OUTDIR);
for i=1:size(list,1)
  fname=strcat(OUTDIR,'/',num2str(i,'%04d'),'.jpg')
  websave(fname,list{i});
end

% 直接，Webから画像を読み込むことこともできます．
% webread でMATLABから直接ダウンロードしてみます．
% セル変数 img に画像が読み込まれます．

for i=1:size(list,1)
  img{i}=webread(list{i});
end

% 確かに5枚分の画像データが読み込まれています．
>> img
img =
    [199x300x3 uint8]    [199x300x3 uint8]    [240x300x3 uint8]
    [225x300x3 uint8]    [200x300x3 uint8]

```

【注意】Webから画像を収集すると，JPEG/PNGであっても，RGB画像でなくて，グレースケールの画像が含まれることがあります．グレースケール画像は `imread` すると `[200x320 uint8]` となってしまって，`x3` がありませんので，`img(y,z,1)` などとするとエラーになります．`x3`があるかどうかは，`ndims(img)` の値が3であるかどうかで確認できます．`ndims(img)` の値が2の場合はグレースケール画像なのでその画像は無視するようにするか，事前にファイルディレクトリからグレースケール画像は削除しておくようにしましょう．また，ファイル名が，`.jpg`でも，中身はPNG，もしくはその逆の場合があります．ブラウザでは表示できますが，MATLABの `imread` ではエラーで読み込めないようです．そのような画像は削除してしまうか，ファイル名を変更しましょう．

なお，MATLABで指定ディレクトリのファイル一覧を取得する方法は，2回目の最後に示したサンプルプログラムを参考にして下さい．

なお，ディレクトリ中の画像の一覧を見るだけなら，UNIXの `nautilus` コマンド，もしくは `gthumb` コマンドでファイルマネージャを起動すると簡単です．

#### 【Python icrawler を使う方法】

Google/Bing Image Search APIは有償ですが，通常のGoogle/Bing Image Searchは無料で利用可能です．そこで，プログラムの中で通常のWebブラウザでのアクセスをシミュレートして，画像を取得するicrawlerというPythonのライブラリが公開されています．
Image Search Engineにクエリーを投げて，戻ってきたHTMLから画像のURLなどの必要な情報を抜き出すことで，画像URLを取得して，元のサイトから画像をダウンロードします．Webページから情報を抽出することをスクレイピング(Web scraping)といい，APIが提供されていない場合のデータ収集手段として使われています．Web search engineのクローラーもスクレイピングをして情報を収集しています．

では，以下のコードを `crawler.py` としてファイルにセーブしてください．

```python
google=True
#google=False

if google:
    from icrawler.builtin import GoogleImageCrawler
    crawler = GoogleImageCrawler(storage={"root_dir":"img"},downloader_threads=5)
else:
    from icrawler.builtin import BingImageCrawler
    crawler = BingImageCrawler(storage={"root_dir":"img"},downloader_threads=5)
    
crawler.crawl(keyword="ramen", max_num=100)

```

以下のように，`pip install --user {モジュール名}` で，各自のhomeに icrawlerモジュールをインストールして利用して下さい．remote.ied でも，sol.edu でも，pythonがインストールされた任意のunix環境で利用可能です．

そして，`crawler.py` があるディレクトリにcdして，`python crawler.py` で実行してください．`img` というディレクトリが作られて，そこに "ramen" 画像が 100枚ダウンロードされます．5スレッドで並列ダウンロードするので高速です．

6行目の"img"が画像をダウンロードするディレクトリ名，7行目の"ramen"が検索ワードです．検索ワードは日本語でも大丈夫ですので，試してみてください．

結果はGoogle画像検索(ただし未ログイン状態，ログインすると個人適応した結果になります)，Bing画像検索と同じはずですので，どんな画像が集まるかは事前に[疑わしいリンクは削除されました], [疑わしいリンクは削除されました]で確認しておいてください．他にもBaiduの画像検索も使えますので，詳しく知りたい人は(英語ですが)[icrawler document](https://icrawler.readthedocs.io/)で調べてください．

```bash
pip install --user icrawler
python3 crawler.py

```

IEDのUbuntu計算機ならどれでも上記の方法で画像をダウンロードできます．

なお，icrawerでダウンロードした画像は，サイズもアスペクト比もがまちまちで，白黒画像が含まれている場合や，ダウンロードに失敗して0バイトのファイルになっている場合，ファイル名は .jpg でも中身は .pngやテキストファイル(file not found メッセージなど)になっている場合など，様々な場合がありますので，多めに収集して，白黒画像や読み込みできない画像は削除してしまいましょう．ファイルブラウザを使って削除してしまうのがいいでしょう．`nautilus {ディレクトリ名}` で表示できます．

他にも，[AutoCrawler](https://github.com/YoongiKim/AutoCrawler)というのもあります．これはブラウザをコントロールして，人間の操作をシミュレートして画像収集するものです．icrawlerでうまくいかない場合は試してみましょう．

---

### 参考情報

【BoFでの点のサンプリング】
レポート課題では，BoFを作成する場合は，detectSURFfeatures関数ではなくて，第4回目で提供した `createRandomPoints` 関数を使って dense sampling して下さい．こちらは，画像に応じて特徴的な点を sparse samplingする代りに，ランダムで特徴点の位置とスケールをdense samplingによって抽出します．Sparse samplingだと均一な背景（空や均一色の壁など）からは特徴点がでないので，実は，物体の分類にはrandom samplingによる特徴点抽出の方が高い精度が出ることが多いということが多くの実験から示されています．ですので，**createRandomPoints関数を使うようにしてください．サンプリングする点の数は，1画像に付き2000～3000くらいが望ましいですが，時間がかかりすぎてしまう場合は，`points=createRandomPoints(I,1000);` として，1画像1000点として構いません．**

コードブックサイズは 1000 がいいでしょう．(時間が掛かり過ぎる場合は，500でも構いません．)

【非線形SVMの使い方】
非線形SVMを用いた分類では，データによっては(カーネルデフォルトの定数とデータの分布の)スケールが合わなくて，上手く分類出来ないことがあります．ですので，非線形SVMを使う場合は，常に `KernelScale auto` オプションを付けることとして，以下のようにして下さい．

```matlab
  model=fitcsvm(training_data, training_label,'KernelFunction','rbf', 'KernelScale','auto');

```

【Web収集データの利用に関する法律的問題】
日本の現在の法律では，Webから収集したデータをAIの学習データに利用することは問題ないとされています．【著作権法第三十条の四】の「情報解析」がそれに当たるとされています．ただし，日本国内の計算機上で収集した場合のみに適用されるので，online MATLABが海外のクラウド上で動いていた場合にはonline MATLABのwebsave関数で収集した場合は適用されないので，注意が必要です．(online MATLABがどこで動いているかはわかりません．)

> **【著作権法第三十条の四】**
> 著作物は、次に掲げる場合その他の当該著作物に表現された思想又は感情を自ら享受し又は他人に享受させることを目的としない場合には、その必要と認められる限度において、いずれの方法によるかを問わず、利用することができる。ただし、当該著作物の種類及び用途並びに当該利用の態様に照らし著作権者の利益を不当に害することとなる場合は、この限りでない。
> 一　著作物の録音、録画その他の利用に係る技術の開発又は実用化のための試験の用に供する場合
> 二　情報解析（多数の著作物その他の大量の情報から、当該情報を構成する言語、音、影像その他の要素に係る情報を抽出し、比較、分類その他の解析を行うことをいう。第四十七条の五第一項第二号において同じ。）の用に供する場合
> 三　前二号に掲げる場合のほか、著作物の表現についての人の知覚による認識を伴うことなく当該著作物を電子計算機による情報処理の過程における利用その他の利用（プログラムの著作物にあつては、当該著作物の電子計算機における実行を除く。）に供する場合

---

### レポート課題

# レポート課題 について

### レポート課題１ (2クラス物体分類実験)

ラーメン/それ以外，ラーメン/そば　のように異なる2クラスの画像データセットをWeb収集画像から人手で選択して作成しましょう．それぞれ100～200枚，同じ枚数ずつ集めましょう．もう一方の分類クラスが「それ以外」の場合は，`/usr/local/class/object/bgimg` にあるランダム画像をネガティブ画像として，ポジティブ画像の2倍の枚数選んで利用してください．(Online MATLABや自宅PCの場合は，[bgimg.zip](https://mm.cs.uec.ac.jp/object/text/bgimg.zip)を右クリックでダウンロードして使ってください．) (なお，ある物体/それ以外 の場合は「それ以外」の方がバリーションがはるかに多いので，「それ以外」の場合は「それ以外」の学習データは多目にします．)

Webから収集した画像にはノイズが入っているので，一度画像ファイルをダウンロード（上記のやり方だと，`websave`コマンドを使いましょう）してから，UNIXの `nautilus` コマンド，もしくは `gthumb` コマンドでファイルマネージャを起動して，目で見て確認して，明らかに間違っている画像はDELキーで削除してしまいましょう．

Online MATLABの場合は，画像のディレクトリに入って，最初の画像を右クリックして「プレビュー」を選択しましょう．画像が1枚だけプレビューできます．下向のカーソルキーで下にフォーカスを移動すると次々にプレビュー画像が変りますので，それで目視でチェックしてノイズ画像を消去することもできます．

そして，2クラス画像分類を行いましょう．**評価は，5-fold cross validationで行ってください．**ポジティブ，ネガティブのそれぞれをデータをランダムに5分割して，そのうち4つを学習データ，残りの1つをテストデータとして分類します．これをテストデータを入れ替えて5回繰り返して，5回分の分類率の平均値を実験結果とします．cross validationの詳細は[こちらのPDF](https://mm.cs.uec.ac.jp/object/text/classify.pdf) の最後から2番目のページを見てください．練習問題の学習データを分類していた簡易的な評価方法とは異なりますので，注意して下さい．

実験は「ラーメン/カレー」と「そば/うどん」の様に2種類以上の2クラスの組み合わせで行ってください．1つの組み合わせは分類が容易な組み合わせ，もう一つの組み合わせは分類が難しそうな組み合わせにしましょう．

分類方法は，

* (1) カラーヒストグラムと最近傍分類(SVMでも可) (カラーヒストグラムは第２回目の練習問題参照)，
* (2) BoFベクトルと非線形SVMによる分類，
* (3) AlexNetやVGG16などによるDCNN特徴量と線形SVM

による分類の３つを試してみて比較しましょう．一般には，分類精度は，(3) > (2) > (1) > ランダム分類(50%) の順番になります．ここでは2クラス分類ですので，ランダムで分類しても精度の期待値は50%です．(3)が一番にならず，また50%未満の分類精度が出た場合はバグの可能性が高いので，再度プログラムを確認して下さい．DCNN特徴は通常は80%以上，最低でも70%以上になりますので，それより低い場合はプログラムを見直してください．

余裕のある人は，ナイーブベイズ，BOF+線形SVM+feature mapsや，ResNetやDenseNetによるDCNN特徴量と線形SVM，DCNN特徴と非線形SVMの組み合わせなども試してみてください．(逆に余裕のない人は，1種類だけの2クラス分類実験でも構いません．さらに余裕がない場合は，DCNN特徴だけ実験してください．)

なおBoFの場合は，コードブックは最初にすべてのデータを用いて作成し，次にそれを使って，すべての画像をbag-of-visual-words ベクトルに変換して下さい．その後，5-fold cross validationによって分類実験を行って下さい．4/5のデータで学習モデルを作成し，1/5のデータを分類して評価，をそれぞれ5回ずつ行って下さい．厳密に行う場合は，fold毎に学習データのみでコードブックを作成して評価実験を行うこともありますが，コードブック作成とbag-of-visual-wordsベクトル生成には時間が掛かるので，簡略化して共通で行うやり方が一般的です．なお，最近傍分類では，テストデータの各画像について最も距離の近い(もしくは類似度が高い)学習データの画像を探して分類すればよいので，5-fold cross validationは可能です．

Webからダウンロードした画像の大きさはまちまちですので，2回目で説明した `imresize` 関数で大きさをできるだけ統一しましょう．ただし，一律に320x240としてしまうと，縦長の画像を無理やり横長にしてしまって正しく特徴抽出ができませんので，縦横比(アスペクト比)は保持したままで，画素数がほぼ同じになるように縮小する方が望ましいです．なお，BingやFlickrのサムネイル画像は，最初からリサイズされてサイズが統一されていますので，特にリサイズの必要はないでしょう．

### レポート課題２ (Web画像検索リランキング実験)

まずFlickrのrelevanceもしくはicrawlerを使ってGoogle Image Searchから，あるキーワードについて50枚画像を収集しましょう．そのうち検索エンジンのランキング上位n枚(n=25 or 50)を**間違いが含まれていても気にせずn枚すべてをそのまま**ポジティブ学習画像とします．ネガティブ学習画像は，`/usr/local/class/object/bgimg` にあるランダム画像を500～1000枚程度利用しましょう．

そして，学習画像すべてからDCNN特徴(AlexnetもしくはVGG-16)を抽出し，線形SVMを学習します．

次に，Flickrのlatest/interestingなどでノイズが多い画像セット300枚を収集しましょう．DCNN特徴(Alexnet, VGG-16, ResNet, DenseNetなど好きなネットワークを使いましょう)を抽出して，それらをテスト画像として，上位画像で学習したSVMモデルで分類し，SVMの出力スコアの大きい順(降順)にソートしましょう．SVMスコアとは，predict関数の返り値を2つにした場合の，2番目の変数に返される値のことです．分離超平面からの各データ点の距離を表し，ネガティブ領域に分類された場合は負の値になります．

(score の各行は (ネガティブサンプルとした場合の距離，ポジティブサンプルとした場合の距離) の順番になっていますので，`score[:,2]` をスコアとして使ってソートして下さい．labelの値は，score値が正の場合に1，負の場合に-1になっています．なお，リランキング課題の場合は，ポジティブサンプルがネガティブサンプルに比べて少ないので，SVMスコアは通常は負に偏ります．出力がすべて負になる場合もありますが，その場合も値の符号は気にせずに，大きい順にランキングしてください．たとえ1位の値が負であっても，正しい画像が上位にランキングされているはずです．)

なお，集めた画像300枚すべてがキーワードに関係している，もしくは上位n枚に１枚も関係画像がない場合（つまり精度が良すぎる，もしくは悪すぎる場合）は，今回の問題設定には適していませんので，Flickr APIの5種類(latest, oldest, interesting, less instersting, relevance)のORDERをいろいろ変えてみて，ちょうどよさそう(少なくとも半分程度は正解画像が含まれる)ORDERで収集してください．(icrawlerでGoogle/BingはノイズがFlickrよりも少ないので，学習画像に使ってください．リランキング対象画像には向いていません．) また，どれもノイズが多すぎるときは，例えば，「[sushi](http://mm.cs.uec.ac.jp/tutorial/flickr.cgi?WORD=sushi)」の場合は「[delicious sushi](http://mm.cs.uec.ac.jp/tutorial/flickr.cgi?WORD=delicious+sushi)」などとキーワードを追加して，対象を限定すると，ノイズが減る場合があります．

```matlab
[label,score] = predict(SVMModel,X);

% 降順 ('descent') でソートして，ソートした値とソートインデックスを取得します．
[sorted_score,sorted_idx] = sort(score[:,2],'descend');

% list{:} に画像ファイル名が入っているとして，
% sorted_idxを使って画像ファイル名，さらに
% sorted_score[i](=score[sorted_idx[i],2])の値を出力します．
for i=1:numel(sorted_idx)
  fprintf('%s %f\n',list{sorted_idx[i]},sorted_score[i]);
end

```

n は，25 と 50 の2通りで試してみてください．そして，再ランキングなしの元のFlickr画像検索の結果の上位100枚中の正解画像枚数と，画像認識を用いて再ランキングした結果の上位100枚中の正解画像枚数を数えてみて正解枚数を比較してみましょう．(何が正解かは自分で基準を決めてカウントしてください．例えば，ラーメン画像にカップラーメンは含めるor含めない，などです．)
**キーワードは２種類以上試してみて下さい．**
結果は，[この様](https://www.google.com/search?q=http://mm.cs.uec.ac.jp/yanai/svm/%3FRUN%3D10%26WORD%3D9%26NEG%3D0%26AB%3D0%26OFFSET%3D0%26UNIT%3D100) のようになれば，成功です．（改善されない場合は，通常はプログラムミスが原因のことが多いですが，学習画像が良くない場合もあるので，必ず学習に使ったFlcikr/Bing画像が適切か目視して確認してみてください．)

画像検索エンジン(Google/Bing)は一般にクリックデータや簡単な画像認識を行って上位によい画像が集められていますので，学習データに向いています．一方，Flickrは単にアップしたユーザが付けたコメントやキーワードに基づいて検索しているので，多くのノイズが混じっていますので，よいデータで学習したモデルでランキングを行うと，よい画像を上位にリランキングすることができるでしょう．

これによって，Flickr画像検索エンジンの出力結果を，Google Image Searchの上位画像と物体認識技術を使って，再ランキング(re-ranking)したことになります．一般には，検索結果が改善されることになります．

---

### レポート提出方法

最終的に上記の2つの課題を両方実施して，レポートにまとめて，PDFで提出してください．

**レポートは，今までの練習問題の提出とは違って，「プログラミング演習」や他の実験のレポートと同様に以下のような正式なレポートの形式で書いてください．**

1. **表紙．**学籍番号，氏名，レポートのタイトル，を記す．
2. **目次．**Latexなら `\tableofcontents` で簡単に作れます．WORDでも，同様に目次が自動で作れるでしょう．
3. **課題内容の説明．**どのようなものを作って，何を実験したか．
4. **設計方針．**どのように作ったか．Mファイルを複数作った場合は，どのMファイルがどのような機能を持っているか説明する．課題１，課題２で共通の部分はまとめて書いて下さい．異なる部分は別々に書いて下さい．
5. **プログラムの説明．**作成したプログラムを簡単に説明して下さい．
6. **実験．**どのようなデータを収集したか説明した上で，実験結果を示して下さい． 表やグラフを作成して，手法による結果の違いを比較して下さい．また結果の画像例も載せましょう．正しく認識できた例，間違った例の両方があるといいでしょう．
7. **考察．**実験結果について考察を書いて下さい．
8. **感想．**
9. **付録１：レポート課題１のプログラムリスト**
最低限のコメントは付ける．`cat -n` コマンドなどで行番号を付与する．
10. **付録２：レポート課題２のプログラムリスト**
最低限のコメントは付ける．`cat -n` コマンドなどで行番号を付与する．

なお，付録１，２は githubへのリンクでも代用可能です．

結果の画像も必ずレポートに載せてください. すべては載せる必要はありませんが，上位の画像は掲載してください．MATLABで多くの画像を表示すると各画像が小さくなりすぎてしまうので，必要に応じて，Linux上で動作する[HTML生成スクリプト](https://mm.cs.uec.ac.jp/object/text/html_pl.txt)(右クリックで `html.pl` として保存して下さい．Perlで書かれていますが，これと同じHTMLをprint出力するコードを任意の言語で用意すれば，同等のことができます．自作する場合は，[出力サンプル](https://mm.cs.uec.ac.jp/object/text/ranked_img.html)のHTMLを参考にして下さい．)を利用してHTMLを生成して，ブラウザで表示してキャプチャーしてみてください．
Linux上で，

```bash
perl html.pl 画像があるディレクトリ名 > img.html
/usr/local/bin/firefox img.html

```

とすると，firefoxで画像が一覧が表示出来ます．(Windows上では動きませんので，注意して下さい．)
Firefoxの場合は，FireShotというプラグインを使うときれいにキャプチャできます．

Webリランキングの場合は，順位が重要ですので，指定したファイル名順に画像を出力するスクリプトも用意しました．以下の様な中身のファイル `list.txt` を用意します．

```text
lion/105024.jpg 1.4224
lion/105070.jpg 1.2344
lion/105074.jpg 1.1333
lion/105043.jpg 0.8123
lion/105094.jpg 0.7123

```

[HTML生成スクリプト](https://mm.cs.uec.ac.jp/object/text/rank_pl.txt)(右クリックで `rank.pl` として保存して下さい．)を利用してHTMLを生成して，ブラウザで表示してキャプチャーしてみてください．
Linux上で，

```bash
perl rank.pl 画像リストファイル名(この場合はlist.txt) > ranked_img.html
/usr/local/bin/firefox ranked_img.html

```

とすると，[画像一覧](https://mm.cs.uec.ac.jp/object/text/ranked_img.html)が表示出来ます．

なお，MATLABで結果をファイル出力するには，C言語とほぼ同じで，`fopen`, `fprintf`, `fclose`を用います．以下にサンプルを示します．

```matlab
FID = fopen('exp.txt','w');
fprintf(FID,'%s %.5f\n',filepath,score);
fclose(FID);

```

[課題提出・確認ページの一番下](https://mm.cs.uec.ac.jp/object/report.html) です．
**<font color="red">提出締切りは2月21日(金)23:59(JST,日本標準時間)です．</font>** (ただし，卒業予定者は2月17日(月)9:00(JST)とします．これに遅れると卒業単位にはカウントされませんので，注意してください．）

**レポート課題はレポート本体のPDFに加えて，課題１のソースコード(mファイル)をまとめたZIPファイルを「ソースコード１」，課題２のソースコードをまとめたZIPファイルを「ソースコード２」としてそれぞれ提出して下さい．**

**提出フォームのレポート本体のテキストコメント入力欄は空白で構いませんが，ソースコードのコメント欄には各mファイルの役割を簡単に書いて下さい．**

なお，レポート提出システムは通常の練習課題提出と同様で，テキストコメント,PDF,ZIPはどれも後から修正・差し替えが可能です．

### [自宅のWindowsからIEDのMATLABを使う方法](https://mm.cs.uec.ac.jp/object/text/win.html)

[ここ](https://mm.cs.uec.ac.jp/object/text/win.html) を参考にしてください．

---

# 第7回目の質問 (提出任意)

質問などがあれば書いて下さい．TAが回答します．

---

# 第8回目の質問 (提出任意)

質問などがあれば書いて下さい．TAが回答します．

---

*電気通信大学 学域I類 メディア情報学プログラム 6学期 物体認識論演習 資料*
*Last modified: Tuesday, 23-Dec-2025 22:15:31 JST*